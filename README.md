# Elasticsearch-OpenAI-RAG-Workflow

Chat with your own data - LLM+RAG

For this workshop, you need:

- Docker
- Python 3 (we use 3.10)
- GitHub account + VS Code (optional - if you want to use codespaces, already contains Docker and Python)
- OpenAI account (optional - possible to replace with a local LLM)
- HuggingFace account (optional - if you want to access some open-source LLMs in the extended version)

## Plan

- Preparing the environment (codespaces)
- Installing pipenv and direnv
- Running ElasticSearch
- Indexing and retrieving documents with ElasticSearch
- Generating the answers with OpenAI

**Future Plan:**

- Creating a web interface with Streamlit
- Running LLMs locally
- Replacing OpenAI with Ollama
- Running Ollama and ElasticSearch in Docker-Compose
- Using Open-Source LLMs from HuggingFace Hub